{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "from functools import partial\n",
    "from bs4 import BeautifulSoup\n",
    "from xml.dom import minidom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(filename: str, encoding='cp1251'):\n",
    "     with open(filename, \"r\", encoding=encoding) as csvfile:\n",
    "        lines = csv.reader(csvfile, delimiter=',')\n",
    "        return list(map(lambda x: list(map(str, x)), lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_str(s):\n",
    "    return s.lower().replace(\"ё\", \"е\")\n",
    "\n",
    "class Morphem:\n",
    "    def __init__(self, normal, clazz, variations):\n",
    "        self.normal_form = normalize_str(normal)\n",
    "        self.clazz = clazz\n",
    "        self.variations = set(map(normalize_str, variations))\n",
    "        self.variations.add(normal)\n",
    "    \n",
    "    def upd_norm(self, new_norm):\n",
    "        self.normal_form = normalize_str(new_norm)\n",
    "        \n",
    "        \n",
    "def odict_to_morph(t: str):\n",
    "    if t in ['мо', 'жо', 'мо-жо', 'м', 'ж', 'мн.', 'с', 'со']:\n",
    "        return \"S\"\n",
    "    if t in ['св', 'св-нсв', 'нсв']:\n",
    "        return \"V\"\n",
    "    if t in ['п', 'числ.-п', 'мс-п']:\n",
    "        return \"A\"\n",
    "    if t in ['союз']:\n",
    "        return \"CONJ\"\n",
    "    if t in ['предл.']:\n",
    "        return \"PR\"\n",
    "    if t in ['н', 'межд.', 'част.', 'предик.', 'вводн.', 'сравн.']:\n",
    "        return \"ADV\"\n",
    "    if t in ['числ.', 'мс']:\n",
    "        return \"NI\"\n",
    "    raise ValueError(\"Unknown type {}\".format(t))\n",
    "    \n",
    "opco_known = ['NOUN', 'ADJF', 'ADJS', 'COMP', 'GRND', 'INFN', 'VERB', 'PRTF', 'PRTS', 'PREP', 'CONJ', 'ADVB', 'INTJ', 'PRCL', 'NPRO', 'PRED', 'NUMR']\n",
    "    \n",
    "    \n",
    "def opco_to_morph(t: str):\n",
    "    if t in ['NOUN']:\n",
    "        return \"S\"\n",
    "    if t in ['ADJF', 'ADJS', 'COMP']:\n",
    "        return \"A\"\n",
    "    if t in ['GRND', 'INFN', 'VERB', 'PRTF', 'PRTS']:\n",
    "        return \"V\"\n",
    "    if t in ['PREP']:\n",
    "        return \"PR\"\n",
    "    if t in ['CONJ']:\n",
    "        return \"CONJ\"\n",
    "    if t in ['ADVB', 'INTJ', 'PRCL']:\n",
    "        return \"ADV\"\n",
    "    if t in ['NPRO', 'PRED', 'NUMR']:\n",
    "        return \"NI\"\n",
    "    raise ValueError(\"Unknown type {}\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphems = []\n",
    "\n",
    "for line in read_csv('odict.csv'):\n",
    "    new_morphem = Morphem(line[0], odict_to_morph(line[1]), line[2:])\n",
    "    # morphems.append(new_morphem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 NOUN ['ёж', 'ежа', 'ежу']\n",
      "2 NOUN ['ёж', 'ежа', 'ежу']\n",
      "3 NOUN ['ёжик', 'ёжика', 'ёжику']\n",
      "4 ADVB ['ёжиком']\n",
      "5 ADJF ['ёжистый', 'ёжистого', 'ёжистому']\n",
      "6 ADJS ['ёжист', 'ёжиста', 'ёжисто']\n",
      "7 COMP ['ёжистее', 'ёжистей', 'поёжистее']\n",
      "8 VERB ['ёжу', 'ёжим', 'ёжишь']\n",
      "9 INFN ['ёжить']\n",
      "10 PRTF ['ёжимый', 'ёжимого', 'ёжимому']\n",
      "11 PRTS ['ёжим', 'ёжима', 'ёжимо']\n",
      "12 GRND ['ёжа', 'ёжив', 'ёживши']\n",
      "13 VERB ['ёжусь', 'ёжимся', 'ёжишься']\n",
      "14 INFN ['ёжиться']\n",
      "15 PRTF ['ёжащийся', 'ёжащегося', 'ёжащемуся']\n",
      "16 PRTF ['ёжившийся', 'ёжившегося', 'ёжившемуся']\n",
      "17 GRND ['ёжась', 'ёжившись']\n",
      "18 VERB ['ёкнул', 'ёкнула', 'ёкнуло']\n",
      "19 INFN ['ёкнуть']\n",
      "20 PRTF ['ёкнувший', 'ёкнувшего', 'ёкнувшему']\n",
      "21 GRND ['ёкнув', 'ёкнувши']\n",
      "22 NOUN ['ёлка', 'ёлки', 'ёлке']\n",
      "23 NOUN ['ёлочка', 'ёлочки', 'ёлочке']\n",
      "24 ADJF ['ёлочный', 'ёлочного', 'ёлочному']\n",
      "27 ADJF ['ёмкий', 'ёмкого', 'ёмкому']\n",
      "28 ADJS ['ёмок', 'ёмка', 'ёмко']\n",
      "29 COMP ['ёмче', 'поёмче']\n",
      "30 ADJF ['ёмкостный', 'ёмкостного', 'ёмкостному']\n",
      "31 ADJS ['ёмкостен', 'ёмкостна', 'ёмкостно']\n",
      "32 COMP ['ёмкостнее', 'ёмкостней', 'поёмкостнее']\n",
      "33 NOUN ['ёмкость', 'ёмкости', 'ёмкостью']\n",
      "34 NOUN ['ёра', 'ёры', 'ёре']\n",
      "35 VERB ['ёрзаю', 'ёрзаем', 'ёрзаешь']\n",
      "36 INFN ['ёрзать']\n",
      "37 PRTF ['ёрзающий', 'ёрзающего', 'ёрзающему']\n",
      "38 PRTF ['ёрзавший', 'ёрзавшего', 'ёрзавшему']\n",
      "39 GRND ['ёрзая', 'ёрзав', 'ёрзавши']\n",
      "40 NOUN ['ёрник', 'ёрника', 'ёрнику']\n",
      "41 VERB ['ёрничаю', 'ёрничаем', 'ёрничаешь']\n",
      "42 INFN ['ёрничать']\n",
      "43 PRTF ['ёрничающий', 'ёрничающего', 'ёрничающему']\n",
      "44 PRTF ['ёрничавший', 'ёрничавшего', 'ёрничавшему']\n",
      "45 GRND ['ёрничая', 'ёрничав', 'ёрничавши']\n",
      "46 ADJF ['ёрнический', 'ёрнического', 'ёрническому']\n",
      "47 NOUN ['ёрш', 'ерша', 'ершу']\n",
      "48 NOUN ['ёрш', 'ерша', 'ершу']\n",
      "49 NOUN ['ёршик', 'ёршика', 'ёршику']\n",
      "50 NOUN ['ёршик', 'ёршика', 'ёршику']\n",
      "51 CONJ ['а']\n",
      "391243\n"
     ]
    }
   ],
   "source": [
    "class OpCorpElement(Morphem):\n",
    "    def __init__(self, eid, normal_form, clazz, variations):\n",
    "        super().__init__(normal_form, clazz, variations)\n",
    "        self.eid = eid\n",
    "\n",
    "\n",
    "def find_word_after(aft, pos, s):\n",
    "    aft += '\"'\n",
    "    beg = s.find(aft, pos)\n",
    "    if beg == -1:\n",
    "        return -1, \"\"\n",
    "    beg += len(aft)\n",
    "    end = s.find('\"', beg)\n",
    "    if end == -1:\n",
    "        return -1, \"\"\n",
    "    return end, s[beg: end]\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "links = {}\n",
    "\n",
    "opcorp = {}\n",
    "with open('dict.opcorpora.xml', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.find(\"<lemma \") == -1 and line.find(\"<link \") == -1:\n",
    "            continue\n",
    "        if line.find(\"<lemma \") != -1:\n",
    "            pos, eid = find_word_after('<lemma id=', 0, line)\n",
    "            pos, clazz = find_word_after('<g v=', pos, line)\n",
    "            variants = []\n",
    "\n",
    "            while True:\n",
    "                pos, word = find_word_after(\"<f t=\", pos, line)\n",
    "                if pos == -1:\n",
    "                    break\n",
    "                if word and word not in variants:\n",
    "                    variants.append(word)\n",
    "            cnt += 1\n",
    "            if cnt < 50:\n",
    "                print(eid, clazz, variants[:3])\n",
    "            new_element = OpCorpElement(eid, variants[0], opco_to_morph(clazz), variants[1:])\n",
    "            \n",
    "            if len(new_element.normal_form) > 1 or new_element.clazz != \"S\":\n",
    "                opcorp[eid] = new_element\n",
    "                morphems.append(new_element)\n",
    "            \n",
    "        if line.find(\"<link\") != -1:\n",
    "            _, fr = find_word_after(\"from=\", 0, line) \n",
    "            _, to = find_word_after(\"to=\", 0, line)\n",
    "            _, tp = find_word_after(\"type=\", 0, line)\n",
    "            links[(fr, to)] = tp\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, t in sorted(links.items(), key=lambda x: x[1]):\n",
    "    if p[0] in opcorp and p[1] in opcorp:\n",
    "        opcorp[p[1]].upd_norm(opcorp[p[0]].normal_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "with open('annot.opcorpora.xml', 'r') as file:\n",
    "    for line in file:\n",
    "        if (line.find(\"<token \") != -1):\n",
    "            _, orig_word = find_word_after(\"text=\", 0, line)\n",
    "            orig_word = normalize_str(orig_word)\n",
    "            \n",
    "            pos = line.find(\"<l \")\n",
    "            assert pos != -1\n",
    "            _, lemma = find_word_after(\"t=\", pos, line)\n",
    "            lemma = normalize_str(lemma)\n",
    "            _, grammema = find_word_after(\"<g v=\", pos, line)\n",
    "            if grammema not in opco_known:\n",
    "                continue\n",
    "            clazz = opco_to_morph(grammema)\n",
    "            \n",
    "            stats[orig_word] = stats.get(orig_word, {})\n",
    "            stats[orig_word][clazz] = stats[orig_word].get(clazz, (0, []))\n",
    "            stats[orig_word][clazz] = (stats[orig_word][clazz][0] + 1, stats[orig_word][clazz][1])\n",
    "            stats[orig_word][clazz][1].append(lemma)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141304\n",
      "[('школа', {'S': (89, ['школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа', 'школа'])}), ('злословия', {'S': (12, ['злословие', 'злословие', 'злословие', 'злословие', 'злословие', 'злословие', 'злословие', 'злословие', 'злословие', 'злословие', 'злословие', 'злословие'])}), ('учит', {'V': (17, ['учу', 'учу', 'учу', 'учу', 'учу', 'учу', 'учу', 'учу', 'учу', 'учу', 'учу', 'учу', 'учу', 'учу', 'учу', 'учу', 'учу'])})]\n"
     ]
    }
   ],
   "source": [
    "print(len(stats))\n",
    "print(list(stats.items())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(morphems):\n",
    "    dictionary = {}\n",
    "\n",
    "    for morphem in morphems:\n",
    "        for word in morphem.variations:\n",
    "            if word not in dictionary:\n",
    "                dictionary[word] = []\n",
    "            variants = dictionary[word]\n",
    "            if morphem not in variants:\n",
    "                variants.append(morphem)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = create_dict(morphems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "priority = ['CONJ', 'PR', \"S\", \"V\", \"A\", \"ADV\"]\n",
    "\n",
    "def most_frequent(List): \n",
    "    d = {} \n",
    "    count, itm = 0, '' \n",
    "    for item in reversed(List): \n",
    "        d[item] = d.get(item, 0) + 1\n",
    "        if d[item] >= count : \n",
    "            count, itm = d[item], item \n",
    "    return(itm) \n",
    "  \n",
    "def lemmatize_word(word: str):\n",
    "    word = normalize_str(word)\n",
    "    if word in dictionary:\n",
    "        morphems = list(map(lambda x: (x.normal_form, x.clazz), dictionary[word]))\n",
    "        d = {}\n",
    "        for morph in morphems:\n",
    "            d[morph[1]] = d.get(morph[1], [])\n",
    "            d[morph[1]].append(morph[0])\n",
    "        \n",
    "        pr = None\n",
    "        if word in stats:\n",
    "            pr = max(stats[word].items(), key=lambda x: x[1])[0]\n",
    "            if stats[word][pr][0] * 2 <= sum(map(lambda x: x[0], stats[word].values())):\n",
    "                print(\"Warning! Unsure about word: {}, options: {}, stats: {}\".format(word, morphems, stats[word]))\n",
    "            if pr in d:\n",
    "                morphem = (most_frequent(d[pr]), pr)\n",
    "            else:\n",
    "                morphem = (most_frequent(stats[word][pr][1]), pr)\n",
    "        else:\n",
    "            for p in priority:\n",
    "                if p in d:\n",
    "                    pr = p\n",
    "                    break\n",
    "            morphem = (most_frequent(d[pr]), pr)\n",
    "                \n",
    "        return morphem[0], morphem[1]\n",
    "    else:\n",
    "        if word in stats:\n",
    "            pr = max(stats[word].items(), key=lambda x: x[1])[0]\n",
    "            if stats[word][pr][0] * 2 <= sum(map(lambda x: x[0], stats[word].values())):\n",
    "                print(\"Warning! Unsure about word: {}, options: {}, stats: {}\".format(word, morphems, stats[word]))\n",
    "            return most_frequent(stats[word][pr][1]), pr\n",
    "        return word, \"S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! Unsure about word: велики, options: [('великий', 'A'), ('велик', 'S')], stats: {'A': (10, ['велик', 'велик', 'велик', 'велик', 'велик', 'велик', 'велик', 'велик', 'велик', 'велик']), 'S': (10, ['велик', 'велик', 'велик', 'велик', 'велик', 'велик', 'велик', 'велик', 'велик', 'велик'])}\n"
     ]
    }
   ],
   "source": [
    "with open('dataset.txt', 'r') as file:\n",
    "    with open('answer.txt', 'w') as out:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            tokens = list(filter(None, re.split(' |,|\\.|\\?|!|\\n', line)))\n",
    "            for word in tokens:\n",
    "                lemmatized, clazz = lemmatize_word(word)\n",
    "                out.write(\"{}{{{}={}}} \".format(word, lemmatized, clazz))\n",
    "            out.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
