{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "special = ['beg', 'haps', 'sads', 'excl', 'point', 'myst', 'en', 'не']\n",
    "\n",
    "def word_map_punct(word):\n",
    "    happy_smiles = [':)', ';)', ':-)', ':D', ':P', ';-)', '(:', '(-:', '((']\n",
    "    sad_smiles = [':(', ';(', ':-(', 'D:', ';-(', '):', ')-:', '))']\n",
    "    for smile in happy_smiles:\n",
    "        if smile in word:\n",
    "            return 'haps'\n",
    "    for smile in sad_smiles:\n",
    "        if smile in word:\n",
    "            return 'sads'\n",
    "    if '!' in word:\n",
    "        return 'excl'\n",
    "    if '...' in word:\n",
    "        return 'myst'\n",
    "    if '.' in word:\n",
    "        return 'point'\n",
    "    return word\n",
    "\n",
    "def map_punct(line):\n",
    "    return list(map(word_map_punct, line))\n",
    "\n",
    "text_corpus = []\n",
    "lemmatized_text_corpus = []\n",
    "scores = []\n",
    "cnt = 0\n",
    "with open('texts_train.txt', 'r') as texts:\n",
    "    with open('scores_train.txt', 'r') as scores_file:\n",
    "        for line, score in zip(texts, scores_file):\n",
    "            line = line.rstrip('\\n')\n",
    "            score = int(score)\n",
    "            scores.append(score)\n",
    "            \n",
    "            text_corpus.append((line, score))\n",
    "            lemmatized_text_corpus.append((['beg'] + map_punct(m.lemmatize(line)) + ['en'], score))\n",
    "            cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "score_stats = {i: 0 for i in range(1, 11)}\n",
    "for score in scores:\n",
    "    score_stats[score] += 1\n",
    "\n",
    "plt.bar(score_stats.keys(), score_stats.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score 1. Text: В литературном отношении - ниже плинтуса, но почитать имеет смысл, чтобы понять, как устроены мелкие пакостники.\n",
      "Score 2. Text: Абсолютно согласна с nassy. Автор, ты кто? С чего ты взял, что можешь считать свои банальности истиной? желание возвыситься путем принижения остальных?? так это иллюзия высоты, не более того. Ощущение такое, что книгу \"истина в тезисах\" написал другой Мороз, а не тот, кто написал \"Пособие для гениев\". Короче, дрянь книга. А вот \"Пособие для гениев\" - рекомендую\n",
      "Score 3. Text: Хрень полная! Похоже на переложенный на бумагу квест. Ходят, ищут, каакие-то подсказки неимоверные. Короче, поддерживаю amam - УЖОС!\n",
      "Score 4. Text: Довольно бесхребетно и постыло. Однако, некоторые мометы попросту гениальны. Например, сцена с коммивояжером из самого начала.\n",
      "Score 5. Text: Всё бы, может, и ничего, но эти слёзы-надрывы, надрывы-слёзы... На грани психического срыва, чесслово. И как-то слишком растянуто. Моя психика страдала :)\n",
      "Score 6. Text: Смотрите, сейчас я в первый и, возможно, последний раз напишу как настоящий сноб: \"Было, было... Все это было\". Не совсем так, не совсем то, но общая атмосфера тотальной безнадеги времен перестройки, жизни без денег и веры в завтрашний день просто идеальна. Как уже упомяналось, одна из редких книг, в которых подача соответствует материалу. Однако, если брать чисто литературную ценность, без этих \"документальных\" элементов, то книга -- крепкий среднячок.\n",
      "Score 7. Text: Долго \"въезжала\" в главного героя, не скажу чтоб не понравилось - просто как-то очень жестко, видно, что мужчина писал. К Ольге претензий нет - как всегда легкое и захватывающее чтение.\n",
      "Score 8. Text: Книга хороша, неглупа, но очень уж затянута.\n",
      "Score 9. Text: Я читала эту книгу и потихоньку впадала в истерику - мужчинам не понравится, а женщины - перед тем как прочитать ее, морально подготовьте себя, что вы за раз ее прочтете и потом ночь спать не будете, обдумывая все сюжетные перипетии...\n",
      "Score 10. Text: Это первая осознанная книга в моей жизни - я без ума от нее. Лирическая, трагическая история вначале и счастливый конец. В конце я плакала и в моем детском воображении строились катрины несправедливости и одновременно логичности этой жизни. Все будет хорошо, даже если сейчс хуже некуда...\n"
     ]
    }
   ],
   "source": [
    "samples = {}\n",
    "for line, score in text_corpus[:5000]:\n",
    "    samples[score] = line\n",
    "    \n",
    "for i in range(1, 11):\n",
    "    print(\"Score {}. Text: {}\".format(i, samples[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(words):\n",
    "    return list(filter(lambda x: x in special or x[0] in 'абвгдеёжзийклмнопрстуфхцчшщ' \\\n",
    "                       and x not in russian_stopwords, words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for line, _ in lemmatized_text_corpus:\n",
    "    line = filter_words(line)\n",
    "    res = []\n",
    "    for prev, word in zip([None] + line, line):\n",
    "        if word == 'не':\n",
    "            continue\n",
    "        if prev == 'не':\n",
    "            res.append(\"NOT_\" + word)\n",
    "        else:\n",
    "            res.append(word)\n",
    "    corpus.append(' '.join(res))\n",
    "split_point = 19800\n",
    "    \n",
    "train, train_scores = corpus[:split_point], scores[:split_point]\n",
    "test, test_scores = corpus[split_point:], scores[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5, ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = RandomForestRegressor(max_depth=10, n_estimators=1000)\n",
    "regr.fit(X, train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.0001, copy_X=True, fit_intercept=True, max_iter=10000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Lasso(max_iter=10000, alpha=0.0001)\n",
    "clf.fit(X, train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature excl (0.119989)\n",
      "2. feature not_понравиться (0.092019)\n",
      "3. feature бред (0.079995)\n",
      "4. feature очень (0.050982)\n",
      "5. feature скучно (0.048806)\n",
      "6. feature отличный (0.042369)\n",
      "7. feature point point (0.033131)\n",
      "8. feature плохой (0.029898)\n",
      "9. feature beg (0.028733)\n",
      "10. feature en (0.022153)\n",
      "11. feature потратить (0.022120)\n",
      "12. feature чушь (0.018162)\n",
      "13. feature любимый (0.016153)\n",
      "14. feature хороший (0.014967)\n",
      "15. feature ужас excl (0.011848)\n",
      "16. feature плохо (0.010578)\n",
      "17. feature полный (0.010226)\n",
      "18. feature тупой (0.010217)\n",
      "19. feature скучный (0.009872)\n",
      "20. feature отвратительный (0.009591)\n"
     ]
    }
   ],
   "source": [
    "importances = regr.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in regr.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(min(X.shape[1], 20)):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, features[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11129376875123176"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = vectorizer.transform(test)\n",
    "regr.score(test_X, test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23049910709332078"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.score(X, train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.txt', 'r') as file:\n",
    "    with open('answer.txt', 'w') as out:\n",
    "        qs = []\n",
    "        for line in file:\n",
    "            line = filter_words(['beg'] + map_punct(m.lemmatize(line)) + ['en'])\n",
    "            res = []\n",
    "            for prev, word in zip([None] + line, line):\n",
    "                if word == 'не':\n",
    "                    continue\n",
    "                if prev == 'не':\n",
    "                    res.append(\"NOT_\" + word)\n",
    "                else:\n",
    "                    res.append(word)\n",
    "            qs.append(' '.join(res))\n",
    "        q_X = vectorizer.transform(qs)\n",
    "        ys = clf.predict(q_X)\n",
    "        \n",
    "        for y in ys:\n",
    "            result = round(y / 10 * 12 - 1)\n",
    "            result = max(min(10, int(result)), 1)\n",
    "            out.write(\"{}\\n\".format(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
